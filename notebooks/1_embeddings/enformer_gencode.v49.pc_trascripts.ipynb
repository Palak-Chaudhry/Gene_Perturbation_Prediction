{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43fb36f",
   "metadata": {},
   "source": [
    "# Enformer Feature Extraction for Genomic Sequences\n",
    "\n",
    "Enformer pre-trained model to extract features from genomic sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rspimv58it",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b26197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configure environment\n",
    "os.environ['WANDB_API_KEY'] = '...' # replace with your key\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'  # Set available GPU device\n",
    "\n",
    "# Login to Weights & Biases for experiment tracking\n",
    "!wandb login\n",
    "\n",
    "print(f\"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ruiz0b18r",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b44189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Grelu library for genomic deep learning\n",
    "from grelu.model.models import EnformerPretrainedModel\n",
    "from grelu.io.fasta import read_fasta\n",
    "from grelu.sequence.format import convert_input_type\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o2nstt5qzn",
   "metadata": {},
   "source": [
    "### Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64944bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "SAVE = True\n",
    "SEED = 1182024\n",
    "TARGET_LENGTH = 8192  # Fixed sequence length for padding\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wiy8i2ttzx",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preprocessing\n",
    "\n",
    "### Load and Process Genomic Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffae1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(seq, target_len):\n",
    "    \"\"\"\n",
    "    Pad or truncate sequence to target length.\n",
    "    \n",
    "    Args:\n",
    "        seq: DNA sequence string\n",
    "        target_len: Desired length\n",
    "    \n",
    "    Returns:\n",
    "        Padded/truncated sequence\n",
    "    \"\"\"\n",
    "    if len(seq) > target_len:\n",
    "        return seq[:target_len]\n",
    "    else:\n",
    "        return seq + \"N\" * (target_len - len(seq))\n",
    "\n",
    "# Load sequences from FASTA file\n",
    "input_fasta = \"../../genomic_sequences/gencode.v49.pc_transcripts.gene_names.fa\"\n",
    "\n",
    "sequences = read_fasta(input_fasta)\n",
    "padded_sequences = [pad_sequence(seq, TARGET_LENGTH) for seq in sequences]\n",
    "\n",
    "print(f\"Processed {len(padded_sequences)} sequences padded to length {TARGET_LENGTH} bp.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhjm3kvjmd",
   "metadata": {},
   "source": [
    "## 3. Model Initialization\n",
    "\n",
    "### Load Pre-trained Enformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c74c351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sequences to one-hot encoding format\n",
    "ohes = convert_input_type(\n",
    "    inputs=padded_sequences,\n",
    "    output_type=\"one_hot\",\n",
    "    genome=\"hg38\",\n",
    "    add_batch_axis=True,\n",
    ")\n",
    "\n",
    "print(f\"One-hot encoded shape: {ohes[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oxi671z4s3k",
   "metadata": {},
   "source": [
    "### Convert to One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Enformer pre-trained model\n",
    "feature_extractor = EnformerPretrainedModel(\n",
    "    n_tasks=32,\n",
    "    device=device\n",
    ")\n",
    "feature_extractor = feature_extractor.to(device)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = sum(p.numel() for p in feature_extractor.parameters())\n",
    "print(f\"Model loaded successfully\")\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8tnd7cc3rdi",
   "metadata": {},
   "source": [
    "## 4. Feature Extraction\n",
    "\n",
    "### Generate Embeddings with Enformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c755438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batch processing\n",
    "test_loader = DataLoader(\n",
    "    dataset=ohes,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Extract features from all sequences\n",
    "embeddings = []\n",
    "feature_extractor.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, data in tqdm(enumerate(test_loader), total=len(test_loader), desc=\"Extracting features\"):\n",
    "        # Move data to device\n",
    "        curr_data = torch.tensor(data, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # Get embeddings from model\n",
    "        batch_embeddings = feature_extractor(curr_data).squeeze().detach().cpu().numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "\n",
    "# Convert to numpy array\n",
    "embedding = np.array(embeddings, dtype=np.float32)\n",
    "embedding = np.stack(embedding, axis=0)\n",
    "\n",
    "print(f\"\\nEmbedding shape: {embedding.shape}\")\n",
    "print(f\"Total sequences processed: {len(embedding)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temp1l6hedi",
   "metadata": {},
   "source": [
    "### Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19844ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    output_file = \"../../embeddings/embeddings_enformer_gencode.v49.pc_transcripts.npy\"\n",
    "    np.save(output_file, embedding)\n",
    "    print(f\"Embeddings saved to: {output_file}\")\n",
    "else:\n",
    "    print(\"SAVE is set to False - embeddings not saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chikina_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
